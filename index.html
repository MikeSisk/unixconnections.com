<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<title>UNIX Connections</title>

	<style>
	body {
		max-width: 720px;
	}
	.post {
		margin-left: 10px;
	}
	.article {
		margin-left: 40px;
	}
	</style>
</head>
<body>

<h1>UNIX Connections</h1>
<hr>

<!--  START POST  -->
<div class="post" id="docker-pi">
<h2>Installing Docker on a Raspberry Pi</h2>
<i>November 9, 2019</i>

<div class="article">

<p>The Raspberry Pi is a fantastic low-cost way to experiment with Docker and Kubernetes.</p>

<p>There's several ways to get the latest version of Docker installed on a Raspberry Pi; you can go with the Cypriot project or a full-fledged GUI-based Raspbian installation.</p>

<p>In my case I have a cluster of six Pi I need to configure for a Kubernetes install and I want the latest "Buster" release so I'm going with Raspbian Buster Lite.</p>

<p>After downloading the ISO image you need to burn it to the MicroSD card. On my modern Apple MacBook Pro this isn't as easy as it used to be since there's on SD card slot and all you get is USB-C ports. So, yeah, dongle life it is.</p>

<p>I used this Uni brand card adapter and it works perfectly.</p>

<p>There's all kinds of ways to burn the Raspbian ISO file to the MicroSD card, but I prefer the command-line way.</p>

<p>First, insert the MicroSD card into the reader and do this to see which "disk" device it's assigned to:</p>

<pre>
mike@jurassic ~ % <b>diskutil list</b>
/dev/disk0 (internal, physical):
   #:                       TYPE NAME                    SIZE       IDENTIFIER
   0:      GUID_partition_scheme                        *500.3 GB   disk0
   1:                        EFI EFI                     314.6 MB   disk0s1
   2:                 Apple_APFS Container disk1         500.0 GB   disk0s2

/dev/disk1 (synthesized):
   #:                       TYPE NAME                    SIZE       IDENTIFIER
   0:      APFS Container Scheme -                      +500.0 GB   disk1
                                 Physical Store disk0s2
   1:                APFS Volume Jurassic - Data         161.0 GB   disk1s1
   2:                APFS Volume Preboot                 87.4 MB    disk1s2
   3:                APFS Volume Recovery                528.5 MB   disk1s3
   4:                APFS Volume VM                      1.1 GB     disk1s4
   5:                APFS Volume Jurassic                10.8 GB    disk1s5

/dev/disk2 (external, physical):
   #:                       TYPE NAME                    SIZE       IDENTIFIER
   0:     FDisk_partition_scheme                        *63.9 GB    disk2
   1:             Windows_FAT_32 boot                    268.4 MB   disk2s1
   2:                      Linux                         63.6 GB    disk2s2

mike@jurassic ~ %
</pre>

<p>As you can see, in this case the 64GB MicroSD card I'm using is mounted as /dev/disk2. To write to it we need to unmount it. This is different than "ejecting"; we need to umount it but still leave it attached to the system so we can write to it.</p>

<pre>
mike@jurassic ~ % <b>diskutil umountDisk /dev/disk2</b>
Unmount of all volumes on disk2 was successful
mike@jurassic ~ %
</pre>

<p>Now we're ready to write the downloaded Raspbian image to the MicroSD card.</p>

<pre>
<b>sudo dd bs=1m if=/Users/mike/Downloads/2019-09-26-raspbian-buster-lite.img of=/dev/rdisk2 conv=sync</b>
</pre>

<p>This will take awhile to run and after it completes the image will automatically mount to the system. Leave it this way for the next step.</p>

<p>I run my Raspberry Pi cluster headless, so instead of hooking up a monitor and keyboard to each Pi to configure it there's several features you can enable on the newly imaged MicroSD card to streamline it's headless setup.</p>

<p>First we need to enable ssh so we can login remotely. You can do this by creating an empty file named 'ssh' on the /boot partition.</p>

<p>Next we need to configure networking. I network my cluster via Wifi so we can create a file called wpa_supplicant.conf also on the /boot filesystem and when the Pi boots it'll copy this file and it's contents to the correct location and fire up the network.</p>

<pre>
mike@jurassic ~ % <b>cd /Volumes/boot</b>
mike@jurassic boot % <b>touch ssh</b>
mike@jurassic boot % <b>touch wpa_supplicant.conf</b>
mike@jurassic boot % <b>vi wpa_supplicant.conf</b>
</pre>

<p>Here's the contents I use in wpa_supplicant.conf to attach to my wifi. Change the attributes to match your wifi settings.</p>

<pre>
ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
update_config=1
country=US

network={
    ssid="Cenozoic"
    key_mgmt=WPA-PSK
    psk="trilobite"
}
</pre>
<p>Ok, now we're ready to eject the MicroSD card from the Mac and put it in the Pi and power it up.</p>

<pre>
mike@jurassic ~ % <b>diskutil eject /dev/disk2</b>
Disk /dev/disk2 ejected
</pre>

<p>After you power up the Pi you should be able to login to it via ssh. Of course, you'll need to find out it's IP address. There's several ways you can do this with a wifi headless setting. You can just check your routers MAC table or DHCP settings if you have access. Or yu can use nmap to scan your network and find a list of devices with active ssh ports.</p>

<p>Once you figure that out and ssh in you're ready to configure your Pi with Docker.</p>

<p>Login as the 'pi' user and change the default password to something more secure. I usually like update the OS, too.</p>

<pre>
<b>passwd
sudo apt update
sudo apt full-upgrade -y
sudo reboot</b>
</pre>

<p>After the reboot with an updated system it's time to get docker installed.</p>

<p>First, we need to install some packages we need to install docker:</p>

<pre>
<b>sudo apt-get install apt-transport-https ca-certificates software-properties-common -y</b>
</pre>

<p>Next we need to download and install the docker gpg key:</p>
<pre>
<b>sudo wget -qO - https://download.docker.com/linux/raspbian/gpg | sudo apt-key add -</b>
</pre>

<p>We need to setup the apt channel to fetch the docker pacakges:</p>

<pre>
<b>sudo echo "deb https://download.docker.com/linux/raspbian/ buster stable" | sudo tee /etc/apt/sources.list.d/docker.list</b>
</pre>

<p>Now, we're ready to install Docker. The --no-install-recommends is to work around an issue with aufs-dkms you might run into. It's not needed for the latest versions of Docker so we can skip it and avoid the issue.</p>

<pre>
<b>sudo apt-get update
sudo apt-get install docker-ce --no-install-recommends -y</b>
</pre>

<p>The last step for setup is to enable the pi user to run docker commands:</p>
<pre>
<b>sudo usermod -aG docker pi</b>
</pre>
<p>Logout of the pi account and back in and you should be good to go. Run docker info to check that Docker is running and is the latest version.</p>


&#x269B;
</div>
</div>
<!--  END POST  -->

<!--  START POST  -->
<div class="post" id="s3cmd">
<h2>s3cmd with Multiple AWS Accounts</h2>
<i>August 9, 2011</i>

<div class="article">
<p>Awhile back I was doing a lot of work involving Amazon's Simple Storage Service (aka Amazon S3).</p>

<p>And while tools like <a href="https://panic.com/transmit/">Panic's Transmit</a>, the Firefox S3Fox extension, or even Amazon's own S3 Management Console make it easy to use, sometimes you really just want a stupid-simple command-line tool.</p>

<p>There's a lot of good tools out there, but the one I've been using is <a href="https://s3tools.org/s3cmd">s3cmd</a>. This tool is written in Python and is well documented. Installation on Linux or OS X is simple as is its configuration. And as a longtime Unix command-line user it's syntax is simple. Some examples:</p>

<p>To list your buckets:</p>

<pre>
~ $ s3cmd ls
2010-04-28 23:50 s3://g5-images
2011-01-21 06:42 s3://g5-mongodb-backup
2011-03-21 21:23 s3://g5-mysql-backup
2010-06-03 17:45 s3://g5-west-images
2010-09-02 15:57 s3://g5engineering
</pre>

<p>List the size of a bucket with "human readable" units:</p>

<pre>
~ $ s3cmd du -H s3://g5-mongodb-backup
1132G s3://g5-mongodb-backup/
</pre>

<p>List the contents of a bucket:</p>

<pre>
~ $ s3cmd ls s3://g5-mongodb-backup
2011-08-08 14:43 3273232889 s3://g5-mongodb-backup/mongodb.2011-08-08-06.tar.gz
2011-08-08 21:12 3290592536 s3://g5-mongodb-backup/mongodb.2011-08-08-12.tar.gz
2011-08-09 03:16 3302734859 s3://g5-mongodb-backup/mongodb.2011-08-08-18.tar.gz
2011-08-09 09:09 3308369423 s3://g5-mongodb-backup/mongodb.2011-08-09-00.tar.gz
2011-08-09 14:51 3285753739 s3://g5-mongodb-backup/mongodb.2011-08-09-06.tar.gz
</pre>

<p>Show the MD5 hash of an asset:</p>

<pre>
~ $ s3cmd ls --list-md5 s3://g5-mongodb-backup/mongodb.2011-08-09-06.tar.gz
2011-08-09 14:51 3285753739 07747e3de16138799d9fe1846436a3ce \
s3://g5-mongodb-backup/mongodb.2011-08-09-06.tar.gz
</pre>

<p>Transferring a file to a bucket uses the get and put commands. And if you
forget an option or need a reminder of usage the very complete s3cmd --help
output will likely be all the help you need.</p>

<p>One problem I have with most tools for AWS is managing multiple accounts. Most
of these tools assume you have just one account, but I work with multiple
accounts and switching between them can be cumbersome.</p>

<p>Here's how I work with multiple AWS accounts using s3cmd.</p>

<p>By default s3cmd puts its configuration file in ~/.s3cfg, but you can
override this and specify a configuration file with the -c option.</p>

<p>What I do is create a separate config file with the appropriate credentials for
each account I work with and give them unique names:</p>

<pre>
~ $ ls -1 .s3cfg*
.s3cfg-g5
.s3cfg-tcp
</pre>

<p>Another option is to keep the credentials for the account you use most often in
the standard ~/.s3cfg file and use the -c option when/if you need another
account. I don't like this option because it's too easy to mistakenly use the
wrong account. For example, without a ~/.s3cfg this is what happens when I use
s3cmd without specifying a configuration:</p>

<pre>
~ $ s3cmd ls
ERROR: /Users/mike/.s3cfg: No such file or directory
ERROR: Configuration file not available.
ERROR: Consider using --configure parameter to create one.
</pre>

<p>So, what to do? Using the -c all the time is a PITA. Answer: use Bash aliases!</p>

<p>Here's a subset of the s3cmd aliases I have in my ~/.bashrc file:</p>

<pre>
# s3cmd aliases for different s3 accounts
alias s3g5='s3cmd -c ~/.s3cfg-g5'
alias s3tcp='s3cmd -c ~/.s3cfg-tcp'
</pre>

<p>Now, to list the buckets in my personal account I just do:</p>

<pre>
~ $ s3tcp ls
2011-07-01 06:10 s3://mikesisk-img
2011-07-05 23:16 s3://www.tcpipranch.com
2011-07-01 22:55 s3://www.watch4rocks.com
</pre>

<p>And I can still pass arguments:</p>

<pre>
~ $ s3tcp -H --list-md5 ls s3://mikesisk-img/me.jpg
2011-07-01 06:09 5k 13d7c86bccd8915dd93b085985305394 \
s3://mikesisk-img/me.jpg
</pre>

<p>Just keep in mind that calls to bash aliases from scripts and cronjobs might not work. Plus it's bad form and will come back to bite you one of these days. Just use the long form with -c in these places and keep the aliases for your own interactive command-line usage.</p>

&#x269B;
</div>
</div>
<!--  END POST  -->

<!--  START POST  -->
<div class="post" id="cron">
<h2>Cron and Sewing Needles</h2>
<i>June 13, 2011</i>
<div class="article">

<p>Sometimes, even after years of experience, you still screw up.</p>

<p>Consider this cron entry I put in last night:</p>
<pre>
    # Backup MongoDB every 6 hours, zip it up, and rsync it.
    * */6 * * * ~/bin/backup_mongo.sh
</pre>
<p>I wanted this to run the backup script for MongoDB every six hours. Instead, I got it running every
minute for an hour every six hours. You'd think I'd know better considering I put the next cron in correctly:</p>
<pre>
    # Remove MongoDB backups that are more than 24-hours old.
    00 02 * * * find /db/backup -mtime +1 -exec rm -f {} \;
</pre>
<p>What I meant to do is this:</p>
<pre>
    # Backup MongoDB every 6 hours, zip it up, and rsync it.
    00 */6 * * * ~/bin/backup_mongo.sh
</pre>
<p>Luckily we host our infrastructure at Engine Yard and their staff noticed the CPU spike on this server at midnight and fixed the cron.</p>

<p>Which brings up another point: name your scripts appropriately. In this case a quick scan of cron revealed this script was running a backup and doing that every six hours makes sense. If the script was just named mongo, it's conceivable it could have been a metric collection script that runs every minute for an hour every six hours.</p>

<p>So what do sewing needles have to do with cron? I'm working from home this week and had just finished that MongoDB backup script and was putting it in cron when my daughter came running (Ok, make that hopping) into my office with a large sewing needle in-bedded about 1/4" deep in the arch of her foot. I quickly saved the cron entry to take care of that problem and didn't go back to check my work.</p>

<p>Moral of the story: whenever you set up a new cron job it's a good idea to watch it run and see if it's doing what you think it is. Especially if you think you know what you're doing.</p>

&#x269B;
</div>
</div>
<!--  END POST  -->

<hr>
<address><a href="mailto:msisk@acm.org">msisk@acm.org</a></address>
</body>
</html>
